{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Root Node Attribute Selection for Decision Tree_Info Gain.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dQ8XbPfOgwF0"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benjamindavid03/MachineLearningLab/blob/main/Root_Node_Attribute_Selection_for_Decision_Tree_Info_Gain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Root Node Attribute Selection for Decision Tree using Information Gain\n",
        "\n",
        "<b>Algorithm</b><br/>\n",
        "Step-1 : Keep the original set S as the initial node.\n",
        "\n",
        "Step-2 : On each iteration of the algorithm, iterate through the very unused attribute of the set S and \n",
        "\n",
        "Step-3: calculates Entropy(H) for the attribute.\n",
        "\n",
        "Step-4: calculate Information gain(IG) of the attribute.\n",
        "\n",
        "Step-5: Select the attribute which has the Largest Information gain and that is selected as the required root node."
      ],
      "metadata": {
        "id": "d4l2p3r3hJq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 : Let's first import the dataset from the Cloud.\n"
      ],
      "metadata": {
        "id": "H9l3pipBhHf1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "3XduE3XCe2py",
        "outputId": "d8486603-313a-498a-a568-233720937cc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   stream     slope elevation vegetation\n",
              "0   False     steep      high  chapparal\n",
              "1    True  moderate       low   riparian\n",
              "2    True     steep    medium   riparian\n",
              "3   False     steep    medium  chapparal\n",
              "4   False      flat      high    conifer\n",
              "5    True     steep   highest    conifer\n",
              "6    True     steep      high  chapparal"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8194b93-42c3-4cb7-a6ce-9115897ccede\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stream</th>\n",
              "      <th>slope</th>\n",
              "      <th>elevation</th>\n",
              "      <th>vegetation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>steep</td>\n",
              "      <td>high</td>\n",
              "      <td>chapparal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>True</td>\n",
              "      <td>moderate</td>\n",
              "      <td>low</td>\n",
              "      <td>riparian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>steep</td>\n",
              "      <td>medium</td>\n",
              "      <td>riparian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>steep</td>\n",
              "      <td>medium</td>\n",
              "      <td>chapparal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>flat</td>\n",
              "      <td>high</td>\n",
              "      <td>conifer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>True</td>\n",
              "      <td>steep</td>\n",
              "      <td>highest</td>\n",
              "      <td>conifer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>True</td>\n",
              "      <td>steep</td>\n",
              "      <td>high</td>\n",
              "      <td>chapparal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8194b93-42c3-4cb7-a6ce-9115897ccede')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8194b93-42c3-4cb7-a6ce-9115897ccede button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8194b93-42c3-4cb7-a6ce-9115897ccede');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import requests\n",
        "\n",
        "url_name = 'https://raw.githubusercontent.com/akmand/datasets/master/FMLPDA_Table4_3.csv'\n",
        "url_content = requests.get(url_name, verify=False).content\n",
        "fruits = pd.read_csv(io.StringIO(url_content.decode('utf-8')))\n",
        "fruits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For convenience, we define a function called compute_impurity() that calculates impurity of a feature using either entropy or gini index."
      ],
      "metadata": {
        "id": "cAUcbXQ5hENr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_impurity(feature, impurity_criterion):\n",
        "    \"\"\"\n",
        "    This function calculates impurity of a feature.\n",
        "    Supported impurity criteria: 'entropy', 'gini'\n",
        "    input: feature (this needs to be a Pandas series)\n",
        "    output: feature impurity\n",
        "    \"\"\"\n",
        "    probs = feature.value_counts(normalize=True)\n",
        "    \n",
        "    if impurity_criterion == 'entropy':\n",
        "        impurity = -1 * np.sum(np.log2(probs) * probs)\n",
        "    elif impurity_criterion == 'gini':\n",
        "        impurity = 1 - np.sum(np.square(probs))\n",
        "    else:\n",
        "        raise ValueError('Unknown impurity criterion')\n",
        "        \n",
        "    return(round(impurity, 3))\n",
        "\n",
        "\n",
        "# let's do two quick examples.\n",
        "print('impurity using entropy:', compute_impurity(fruits, 'entropy'))\n",
        "print('impurity using gini index:', compute_impurity(fruits, 'gini'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaP0JZz0fDaw",
        "outputId": "52a06cb7-b643-44e8-990e-86369b8326e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "impurity using entropy: 2.807\n",
            "impurity using gini index: 0.857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A sample way to compute the entropy of the vegetation feature from the dataset"
      ],
      "metadata": {
        "id": "K4q-lRjAPjbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_entropy = compute_impurity(fruits['vegetation'], 'entropy')\n",
        "target_entropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0vSHBfHfgBb",
        "outputId": "05cca4c0-3b0f-49a6-8b74-b9a590e1d813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.557"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 : Compute Entropy"
      ],
      "metadata": {
        "id": "sKL8UQJkPq_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute the information gain for splitting based on a descriptive feature to figure out the best feature to split on. For this task, we do the following:\n",
        "\n",
        "Compute impurity of the target feature (using either entropy or gini index).\n",
        "Partition the dataset based on unique values of the descriptive feature.\n",
        "Compute impurity for each partition.\n",
        "Compute the remaining impurity as the weighted sum of impurity of each partition.\n",
        "Compute the information gain as the difference between the impurity of the target feature and the remaining impurity.\n",
        "We will define another function to achieve this, called comp_feature_information_gain().\n",
        "\n",
        "As an example, let's have a look at the levels of the \"elevation\" feature."
      ],
      "metadata": {
        "id": "wU7_3CLGg6xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fruits['elevation'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6_8-ba-foFM",
        "outputId": "3f25f348-7491-4c1b-938a-38d2c405f49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "high       3\n",
              "medium     2\n",
              "low        1\n",
              "highest    1\n",
              "Name: elevation, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fruits['slope'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D01DPlJzP0Gm",
        "outputId": "7c26bb1b-a8ac-486f-bb57-94b296c4c53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "steep       5\n",
              "moderate    1\n",
              "flat        1\n",
              "Name: slope, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the partitions look like for this feature and what the corresponding calculations are using the entropy split criterion (entropy)."
      ],
      "metadata": {
        "id": "Y-wHhE4Xg-Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for level in fruits['elevation'].unique(): #Series.unique() In this example, unique() method is used to know all type of unique values in Team column.\n",
        "    print('level name:', level)\n",
        "    df_feature_level = fruits[fruits['elevation'] == level]\n",
        "    print('corresponding data partition:')\n",
        "    print(df_feature_level)\n",
        "    print('partition target feature impurity:', compute_impurity(df_feature_level['vegetation'], 'entropy'))\n",
        "    print('partition weight:', str(len(df_feature_level)) + '/' + str(len(fruits)))\n",
        "    print('====================')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z275MbXtft-E",
        "outputId": "48c8d165-623c-4bd8-8e27-e747c782fb85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "level name: high\n",
            "corresponding data partition:\n",
            "   stream  slope elevation vegetation\n",
            "0   False  steep      high  chapparal\n",
            "4   False   flat      high    conifer\n",
            "6    True  steep      high  chapparal\n",
            "partition target feature impurity: 0.918\n",
            "partition weight: 3/7\n",
            "====================\n",
            "level name: low\n",
            "corresponding data partition:\n",
            "   stream     slope elevation vegetation\n",
            "1    True  moderate       low   riparian\n",
            "partition target feature impurity: -0.0\n",
            "partition weight: 1/7\n",
            "====================\n",
            "level name: medium\n",
            "corresponding data partition:\n",
            "   stream  slope elevation vegetation\n",
            "2    True  steep    medium   riparian\n",
            "3   False  steep    medium  chapparal\n",
            "partition target feature impurity: 1.0\n",
            "partition weight: 2/7\n",
            "====================\n",
            "level name: highest\n",
            "corresponding data partition:\n",
            "   stream  slope elevation vegetation\n",
            "5    True  steep   highest    conifer\n",
            "partition target feature impurity: -0.0\n",
            "partition weight: 1/7\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 : Computing Information Gain\n",
        "The idea here is that, for each one of the 4 data partitions above, we compute their impurity with respect to the target feature as a stand-alone dataset.\n",
        "\n",
        "We weigh these impurities with the relative number of observations in each partition. The relative number of observations is calculated as the number of observations in the partition divided by the total number of observations in the entire dataset. For instance, the weight of the first partition is 3/7.\n",
        "We add up these weighted impurities and call it the remaining impurity for this feature.\n",
        "For instance, remaining impurity as measured by entropy for the elevation feature is <p>0.918 x (3/7) + 1.0 x (2/7) = 0.679.</p>\n",
        "\n",
        "Information gain is then calculated as <p style='background-color:red'> 1.557 - 0.679 = 0.878. </p>\n",
        "\n",
        "Now we are ready to define our function. There is a bit of coding in here, but we can assure you that trying to figure out how things work in here will be rewarding to improve your Python programming skills."
      ],
      "metadata": {
        "id": "dQ8XbPfOgwF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def comp_feature_information_gain(df, target, descriptive_feature, split_criterion):\n",
        "    \"\"\"\n",
        "    This function calculates information gain for splitting on \n",
        "    a particular descriptive feature for a given dataset\n",
        "    and a given impurity criteria.\n",
        "    Supported split criterion: 'entropy', 'gini'\n",
        "    \"\"\"\n",
        "    \n",
        "    print('target feature:', target)\n",
        "    print('descriptive_feature:', descriptive_feature)\n",
        "    print('split criterion:', split_criterion)\n",
        "            \n",
        "    target_entropy = compute_impurity(df[target], split_criterion)\n",
        "\n",
        "    # we define two lists below:\n",
        "    # entropy_list to store the entropy of each partition\n",
        "    # weight_list to store the relative number of observations in each partition\n",
        "    entropy_list = list()\n",
        "    weight_list = list()\n",
        "    \n",
        "    # loop over each level of the descriptive feature\n",
        "    # to partition the dataset with respect to that level\n",
        "    # and compute the entropy and the weight of the level's partition\n",
        "    for level in df[descriptive_feature].unique():\n",
        "        df_feature_level = df[df[descriptive_feature] == level]\n",
        "        entropy_level = compute_impurity(df_feature_level[target], split_criterion)\n",
        "        entropy_list.append(round(entropy_level, 3))\n",
        "        weight_level = len(df_feature_level) / len(df)\n",
        "        weight_list.append(round(weight_level, 3))\n",
        "\n",
        "    print('impurity of partitions:', entropy_list)\n",
        "    print('weights of partitions:', weight_list)\n",
        "\n",
        "    feature_remaining_impurity = np.sum(np.array(entropy_list) * np.array(weight_list))\n",
        "    print('remaining impurity:', feature_remaining_impurity)\n",
        "    \n",
        "    information_gain = target_entropy - feature_remaining_impurity\n",
        "    print('information gain:', information_gain)\n",
        "    \n",
        "    print('====================')\n",
        "\n",
        "    return(information_gain)"
      ],
      "metadata": {
        "id": "Yg-HXWp1gAt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our function has been defined, we will call it for each descriptive feature in the dataset. First let's call it using the entropy split criteria."
      ],
      "metadata": {
        "id": "s2diBn4mgfJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 : Find the best feature with the highest impurity and place it at the root node."
      ],
      "metadata": {
        "id": "hEdTacd6RFmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_criterion = 'entropy'\n",
        "for feature in fruits.drop(columns='vegetation').columns:\n",
        "    feature_info_gain = comp_feature_information_gain(fruits, 'vegetation', feature, split_criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXAQjbBDgFc6",
        "outputId": "974304df-b472-4b42-cd42-50260c4682f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target feature: vegetation\n",
            "descriptive_feature: stream\n",
            "split criterion: entropy\n",
            "impurity of partitions: [0.918, 1.5]\n",
            "weights of partitions: [0.429, 0.571]\n",
            "remaining impurity: 1.250322\n",
            "information gain: 0.306678\n",
            "====================\n",
            "target feature: vegetation\n",
            "descriptive_feature: slope\n",
            "split criterion: entropy\n",
            "impurity of partitions: [1.371, -0.0, -0.0]\n",
            "weights of partitions: [0.714, 0.143, 0.143]\n",
            "remaining impurity: 0.9788939999999999\n",
            "information gain: 0.578106\n",
            "====================\n",
            "target feature: vegetation\n",
            "descriptive_feature: elevation\n",
            "split criterion: entropy\n",
            "impurity of partitions: [0.918, -0.0, 1.0, -0.0]\n",
            "weights of partitions: [0.429, 0.143, 0.286, 0.143]\n",
            "remaining impurity: 0.6798219999999999\n",
            "information gain: 0.877178\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step : Now let's call it using the gini index split criteria. (NOT FOR EXAM)"
      ],
      "metadata": {
        "id": "JOfuXS3Fga1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_criteria = 'gini'\n",
        "for feature in fruits.drop(columns='vegetation').columns:\n",
        "    feature_info_gain = comp_feature_information_gain(fruits, 'vegetation', feature, split_criteria)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE5VdppxgQWG",
        "outputId": "69b4deeb-6038-4a93-9daf-b4366a5fba2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target feature: vegetation\n",
            "descriptive_feature: stream\n",
            "split criterion: gini\n",
            "impurity of partitions: [0.444, 0.625]\n",
            "weights of partitions: [0.429, 0.571]\n",
            "remaining impurity: 0.5473509999999999\n",
            "information gain: 0.1056490000000001\n",
            "====================\n",
            "target feature: vegetation\n",
            "descriptive_feature: slope\n",
            "split criterion: gini\n",
            "impurity of partitions: [0.56, 0.0, 0.0]\n",
            "weights of partitions: [0.714, 0.143, 0.143]\n",
            "remaining impurity: 0.39984000000000003\n",
            "information gain: 0.25316\n",
            "====================\n",
            "target feature: vegetation\n",
            "descriptive_feature: elevation\n",
            "split criterion: gini\n",
            "impurity of partitions: [0.444, 0.0, 0.5, 0.0]\n",
            "weights of partitions: [0.429, 0.143, 0.286, 0.143]\n",
            "remaining impurity: 0.333476\n",
            "information gain: 0.31952400000000003\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that, with both the entropy and gini index split criteria, the highest information gain occurs with the \"elevation\" feature.\n",
        "\n",
        "This is the for the split at the root node of the corresponding decision tree. In subsequent splits, the above procedure is repeated with the subset of the entire dataset in the current branch until the termination condition is reached.\n",
        "\n"
      ],
      "metadata": {
        "id": "9fNfW2mMgXvy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "References\n",
        "\n",
        "1. https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
        "2. https://en.wikipedia.org/wiki/Decision_tree_learning#Information_Gain\n",
        "3. http://christianherta.de/lehre/dataScience/machineLearning/decision-trees.php\n",
        "4. https://www.featureranking.com/tutorials/machine-learning-tutorials/information-gain-computation/\n"
      ],
      "metadata": {
        "id": "RudlfAUlfia7"
      }
    }
  ]
}