{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision Tree Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOupsSezZw2mvD/7q/RBXau",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benjamindavid03/MachineLearningLab/blob/main/Decision_Tree_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Classification\n",
        "Decision Tree is one of the most powerful and popular algorithm. Decision-tree algorithm falls under the category of supervised learning algorithms. It works for both continuous as well as categorical output variables.\n",
        "\n",
        "<b>Pseudocode :</b>\n",
        "1. Find the best attribute and place it on the root node of the tree.\n",
        "2. Now, split the training set of the dataset into subsets. While making the subset make sure that each subset of training dataset should have the same value for an attribute.\n",
        "3. Find leaf nodes in all branches by repeating 1 and 2 on each subset.\n",
        "\n"
      ],
      "metadata": {
        "id": "fWwgiraDD87R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "\n",
        "# Function importing Dataset\n",
        "def importdata():\n",
        "\tdata1 = \"https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data\"\n",
        "\tbalance_data = pd.read_csv(data1,\tsep= ',', header = None)\n",
        "\t\n",
        "\t# Printing the dataswet shape\n",
        "\tprint (\"Dataset Length: \", len(balance_data))\n",
        "\tprint (\"Dataset Shape: \", balance_data.shape)\n",
        "\t\n",
        "\t# Printing the dataset obseravtions\n",
        "\tprint (\"Dataset: \\n \",balance_data.head())\n",
        "\treturn balance_data"
      ],
      "metadata": {
        "id": "mnaZHwLlDzBA"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split the dataset\n",
        "def splitdataset(balance_data):\n",
        "\n",
        "\t# Separating the target variable\n",
        "\tX = balance_data.values[:, 1:5]\n",
        "\tY = balance_data.values[:, 0]\n",
        "\n",
        "\t# Splitting the dataset into train and test\n",
        "\tX_train, X_test, y_train, y_test = train_test_split(\n",
        "\tX, Y, test_size = 0.3, random_state = 100)\n",
        "\t\n",
        "\treturn X, Y, X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "-ExgHbG7D5DI"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree construction based on\n",
        "1. Gini Index\n",
        "2. Entropy"
      ],
      "metadata": {
        "id": "O5oBPUYGEAoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terms used in code :\n",
        "Gini index and information gain both of these methods are used to select from the n attributes of the dataset which attribute would be placed at the root node or the internal node.\n",
        "\n",
        "Gini index:\n",
        "\n",
        "<img style=\"color:white\" src=\"https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-135a8a09c5a8a4e0e2afff9cea447727_l3.svg\"/>\n",
        "\n",
        "Gini Index is a metric to measure how often a randomly chosen element would be incorrectly identified.\n",
        "It means an attribute with lower gini index should be preferred.\n",
        "Sklearn supports “gini” criteria for Gini Index and by default, it takes “gini” value.\n",
        "Entropy:\n",
        "\n",
        "  if a random variable $\\mathrm{x}$ can take $\\mathrm{N}$ different value , the i'value $\\mathrm{x}_{\\mathrm{i}}$ with probability $\\mathrm{p}\\left(\\mathrm{x}_{\\mathrm{ii}}\\right)$ ,we can associate the following entropy with $\\mathrm{x}$ : $$ H(x)=-\\sum_{i=1}^{N} p\\left(x_{i}\\right) \\log _{2} p\\left(x_{i}\\right) $$\n",
        "\n",
        "Entropy is the measure of uncertainty of a random variable, it characterizes the impurity of an arbitrary collection of examples. The higher the entropy the more the information content.\n",
        "Information Gain\n",
        "\n",
        "Definition: Suppose $S$ is a set of instances, $A$ is an attribute, $\\mathrm{S}_{\\mathrm{v}}$ is the subset of $\\mathrm{s}$ with $\\mathrm{A}=\\mathrm{v}$ and Values(A) is the set of all possible of A,then\n",
        "The entropy typically changes when we use a node in a decision tree to partition the training instances into smaller subsets. Information gain is a measure of this change in entropy.\n",
        "Sklearn supports “entropy” criteria for Information Gain and if we want to use Information Gain method in sklearn then we have to mention it explicitly."
      ],
      "metadata": {
        "id": "qfB_FewXFBeo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "aLjsPOMCCrBF"
      },
      "outputs": [],
      "source": [
        "# Function to perform training with giniIndex.\n",
        "def train_using_gini(X_train, X_test, y_train):\n",
        "\n",
        "\t# Creating the classifier object\n",
        "\tclf_gini = DecisionTreeClassifier(criterion = \"gini\",\n",
        "\t\t\trandom_state = 100,max_depth=3, min_samples_leaf=5)\n",
        "\n",
        "\t# Performing training\n",
        "\tclf_gini.fit(X_train, y_train)\n",
        "\treturn clf_gini\n",
        "\t\n",
        "# Function to perform training with entropy.\n",
        "def train_using_entropy(X_train, X_test, y_train):\n",
        "\n",
        "\t# Decision tree with entropy\n",
        "\tclf_entropy = DecisionTreeClassifier(\n",
        "\t\t\tcriterion = \"entropy\", random_state = 100,\n",
        "\t\t\tmax_depth = 3, min_samples_leaf = 5)\n",
        "\n",
        "\t# Performing training\n",
        "\tclf_entropy.fit(X_train, y_train)\n",
        "\treturn clf_entropy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make predictions\n",
        "def prediction(X_test, clf_object):\n",
        "\n",
        "\t# Predicton on test with giniIndex\n",
        "\ty_pred = clf_object.predict(X_test)\n",
        "\tprint(\"Predicted values:\\n\")\n",
        "\tprint(y_pred)\n",
        "\treturn y_pred"
      ],
      "metadata": {
        "id": "m9Xw4KVDDurw"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy\n",
        "def cal_accuracy(y_test, y_pred):\n",
        "\t\n",
        "\tprint(\"Confusion Matrix: \",\n",
        "\t\tconfusion_matrix(y_test, y_pred))\n",
        "\t\n",
        "\tprint (\"Accuracy : \",\n",
        "\taccuracy_score(y_test,y_pred)*100)\n",
        "\t\n",
        "\tprint(\"Report : \",\n",
        "\tclassification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "3qrulQxPDs0o"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Phase\n",
        "data = importdata()\n",
        "X, Y, X_train, X_test, y_train, y_test = splitdataset(data)\n",
        "clf_gini = train_using_gini(X_train, X_test, y_train)\n",
        "clf_entropy = train_using_entropy(X_train, X_test, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNLwkRopDqdp",
        "outputId": "31f6f2c7-678e-4c66-8c7b-fe9e621c4d32"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Length:  625\n",
            "Dataset Shape:  (625, 5)\n",
            "Dataset: \n",
            "     0  1  2  3  4\n",
            "0  B  1  1  1  1\n",
            "1  R  1  1  1  2\n",
            "2  R  1  1  1  3\n",
            "3  R  1  1  1  4\n",
            "4  R  1  1  1  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Operational Phase\n",
        "print(\"Results Using Gini Index:\")\t\n",
        "# Prediction using gini\n",
        "y_pred_gini = prediction(X_test, clf_gini)\n",
        "cal_accuracy(y_test, y_pred_gini)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMjwE_92RCv4",
        "outputId": "1d3e7c9d-ac77-4600-b200-2381eab0e15e"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results Using Gini Index:\n",
            "Predicted values:\n",
            "\n",
            "['R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'L'\n",
            " 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L'\n",
            " 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'R'\n",
            " 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'R'\n",
            " 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
            " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'R'\n",
            " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L'\n",
            " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R'\n",
            " 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R'\n",
            " 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R'\n",
            " 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'R']\n",
            "Confusion Matrix:  [[ 0  6  7]\n",
            " [ 0 67 18]\n",
            " [ 0 19 71]]\n",
            "Accuracy :  73.40425531914893\n",
            "Report :                precision    recall  f1-score   support\n",
            "\n",
            "           B       0.00      0.00      0.00        13\n",
            "           L       0.73      0.79      0.76        85\n",
            "           R       0.74      0.79      0.76        90\n",
            "\n",
            "    accuracy                           0.73       188\n",
            "   macro avg       0.49      0.53      0.51       188\n",
            "weighted avg       0.68      0.73      0.71       188\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Results Using Entropy:\")\n",
        "# Prediction using entropy\n",
        "y_pred_entropy = prediction(X_test, clf_entropy)\n",
        "cal_accuracy(y_test, y_pred_entropy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ABnCAlDREXg",
        "outputId": "28251152-a0d8-45a5-b904-2943fe85a9f2"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results Using Entropy:\n",
            "Predicted values:\n",
            "\n",
            "['R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L'\n",
            " 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L'\n",
            " 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L'\n",
            " 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R'\n",
            " 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
            " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'R'\n",
            " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L'\n",
            " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R'\n",
            " 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R'\n",
            " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'R'\n",
            " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R']\n",
            "Confusion Matrix:  [[ 0  6  7]\n",
            " [ 0 63 22]\n",
            " [ 0 20 70]]\n",
            "Accuracy :  70.74468085106383\n",
            "Report :                precision    recall  f1-score   support\n",
            "\n",
            "           B       0.00      0.00      0.00        13\n",
            "           L       0.71      0.74      0.72        85\n",
            "           R       0.71      0.78      0.74        90\n",
            "\n",
            "    accuracy                           0.71       188\n",
            "   macro avg       0.47      0.51      0.49       188\n",
            "weighted avg       0.66      0.71      0.68       188\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "References : \n",
        "\n",
        "1. <a href=\"https://en.wikipedia.org/wiki/Decision_tree\">Decision Tree</a>\n",
        "2. <a href=\"https://en.wikipedia.org/wiki/Decision_tree_learning\">Decision Tree Learning</a>\n",
        "3. <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">Decision Tree Classifier</a>\n",
        "4.   <a href=\"https://github.com/Benjamindavid03/MachineLearningLab\">Machine Learning Lab</a>\n",
        "5.   <a href=\"https://www.geeksforgeeks.org/decision-tree-implementation-python\">Decision Tree Implementation</a>\n",
        "6.   <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\">Classification Report</a>\n"
      ],
      "metadata": {
        "id": "YBcEpDJ2Zfex"
      }
    }
  ]
}